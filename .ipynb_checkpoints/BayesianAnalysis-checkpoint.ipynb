{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Analysis\n",
    "\n",
    "We want to answer the simple question: Is the CAM created by a participant unique?\n",
    "\n",
    "To do this, we will construct N random graphs using *networkx.gnm_random_graph* setting the same number of nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "import networkx as nx\n",
    "import random\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CAM to get nodes and edges\n",
    "file_path = '/home/carterrhea/Dropbox/APLS-CAM-Proposal/DataFinal/Clean' #path to data on local computer\n",
    "\n",
    "#Function to get unique elements from a list\n",
    "def list_unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "            \n",
    "    return unique_list\n",
    "\n",
    "def make_id_list(my_file_path):\n",
    "\n",
    "    #pull all filenames in your data directory\n",
    "    _, _, filenames = next(walk(my_file_path))\n",
    "\n",
    "    #grab only the id from the filenames to feed to the function\n",
    "    id_list = []\n",
    "    for filename in filenames:\n",
    "        filename_split = filename.rsplit('_', 1)\n",
    "        id_list.append(filename_split[0])\n",
    "    \n",
    "    unique_id = list_unique(id_list) #drop duplicate ids, since they are the same for _blocks & _links\n",
    "        \n",
    "    \n",
    "    \n",
    "    return unique_id\n",
    "\n",
    "\n",
    "#Get an id_list from your specific file path\n",
    "my_id_list = make_id_list(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab single to play with\n",
    "cam_id = my_id_list[10]\n",
    "df_blocks = pd.read_csv(f'{file_path}/{cam_id}_blocks.csv')\n",
    "links_df = pd.read_csv(f'{file_path}/{cam_id}_links.csv')\n",
    "#df_blocks\n",
    "df_blocks[df_blocks['shape']=='neutral'].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.0\n"
     ]
    }
   ],
   "source": [
    "# Create distance matrix\n",
    "D = np.zeros((7,7))  # We have seven node types hence 7 (note that we consider ambivalent as the same as neutral in this calculation)\n",
    "dist_ = np.arange(7)\n",
    "for i in range(7):\n",
    "    D[i,i:] = dist_\n",
    "    D[i:,i] = dist_\n",
    "    dist_ = dist_[:-1]\n",
    "\n",
    "def calculate_diversity(D, probs):\n",
    "    \"\"\"\n",
    "    Calculate Stirling Diversity measure with alpha = beta = 1\n",
    "    Args:\n",
    "        param: D - Distance Matrix\n",
    "        param: probs - list of probabilities in order of Strong Negative, Negative, Weak Negative, Neutral, Weak Positive, Positive, Strong Positive\n",
    "    \"\"\"\n",
    "    S = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            S += D[i, j]*probs[i]*probs[j]\n",
    "    return S\n",
    "# Get probabilities of each type of node -- used for diversity calculation\n",
    "neg_strong = df_blocks[df_blocks['shape']=='negative strong'].count()[0]\n",
    "neg = df_blocks[df_blocks['shape']=='negative'].count()[0]\n",
    "neg_weak = df_blocks[df_blocks['shape']=='negative weak'].count()[0]\n",
    "neutral = df_blocks[(df_blocks['shape']=='neutral') & (df_blocks['shape']=='ambivalent')].count()[0]\n",
    "pos_weak = df_blocks[df_blocks['shape']=='positive weak'].count()[0]\n",
    "pos = df_blocks[df_blocks['shape']=='positive'].count()[0]\n",
    "pos_strong = df_blocks[df_blocks['shape']=='positive strong'].count()[0]\n",
    "probs = [neg_strong, neg, neg_weak, neutral, pos_weak, pos, pos_strong]\n",
    "true_div = calculate_diversity(D, probs)\n",
    "print(true_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create n random graphs with the same number of nodes and edges\n",
    "random_graphs = []\n",
    "div_vals = []\n",
    "n_ = 1000\n",
    "for i in range(n_):\n",
    "    random_graph = nx.gnm_random_graph(len(blocks_df), len(links_df))\n",
    "    random_graphs.append(random_graph)\n",
    "    # Get probabilities of each type of node -- used for diversity calculation\n",
    "    neg_strong = df_blocks[df_blocks['shape']=='negative strong'].count()[0]\n",
    "    neg = df_blocks[df_blocks['shape']=='negative'].count()[0]\n",
    "    neg_weak = df_blocks[df_blocks['shape']=='negative weak'].count()[0]\n",
    "    neutral = df_blocks[(df_blocks['shape']=='neutral') & (df_blocks['shape']=='ambivalent')].count()[0]\n",
    "    pos_weak = df_blocks[df_blocks['shape']=='positive weak'].count()[0]\n",
    "    pos = df_blocks[df_blocks['shape']=='positive'].count()[0]\n",
    "    pos_strong = df_blocks[df_blocks['shape']=='positive strong'].count()[0]\n",
    "    probs = [neg_strong, neg, neg_weak, neutral, pos_weak, pos, pos_strong]\n",
    "    # Randomly assign valences to each node\n",
    "    probs_rand = []\n",
    "    for node in random_graph.nodes(data=True):\n",
    "        shape_type_rand = random.choices([-3,-2,-1,0,1,2,3], weights=probs, k=1)[0]\n",
    "        node[1]['shape_num'] = shape_type_rand\n",
    "        probs_rand.append(shape_type_rand)\n",
    "    # Calculate random graph node probabilities\n",
    "    probs_rand = [probs_rand.count(-3), probs_rand.count(-2), probs_rand.count(-1), probs_rand.count(0), probs_rand.count(1), probs_rand.count(2), probs_rand.count(3)]\n",
    "    # Calculate the diversity of each graph\n",
    "    div_ = calculate_diversity(D, probs_rand)\n",
    "    div_vals.append(div_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of instances with a similar diversity\n",
    "insts_div = 0\n",
    "for div_ in div_vals:\n",
    "    if div_ - true_div < 100:\n",
    "        insts_div += 1\n",
    "    else:\n",
    "        pass\n",
    "print(insts_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carterrhea/anaconda3/lib/python3.8/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in true_divide\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Calculate probability of replicating using Bayesian stats\n",
    "alphas = np.array([1, 1])\n",
    "c = np.array([insts_div, n_-insts_div])\n",
    "\n",
    "# Create model\n",
    "with pm.Model() as model:\n",
    "    # Parameters of the Multinomial are from a Dirichlet\n",
    "    parameters = pm.Dirichlet('parameters', a=alphas, shape=2)\n",
    "    # Observed data is from a Multinomial distribution\n",
    "    observed_data = pm.Multinomial(\n",
    "        'observed_data', n=n_, p=parameters, shape=2, observed=c)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-fdb9c5e27e45>:3: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace = pm.sample(draws=1000, chains=2, tune=500,\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 4 jobs)\n",
      "NUTS: [parameters]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3000' class='' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3000/3000 00:20<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 20 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    # Sample from the posterior\n",
    "    trace = pm.sample(draws=1000, chains=2, tune=500, \n",
    "                      discard_tuned_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carterrhea/anaconda3/lib/python3.8/site-packages/arviz/data/io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame._add_numeric_operations.<locals>.mean of                 mean     sd  hdi_3%  hdi_97%\n",
      "parameters[0]  0.036  0.006   0.025    0.048\n",
      "parameters[1]  0.964  0.006   0.952    0.975>\n"
     ]
    }
   ],
   "source": [
    "print(az.summary(trace, kind=\"stats\").mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
